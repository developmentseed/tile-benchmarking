{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330dc8cc",
   "metadata": {},
   "source": [
    "# Profiling tiling of titiler-pgstac and titiler-xarray\n",
    "\n",
    "This notebook profiles code for tiling CMIP6 data via 2 methods:\n",
    "\n",
    "1. pgSTAC + COGs: The first method uses a (local or remote) pgSTAC database for storing metadata about COGs on S3. The libraries used are pgstac for reading STAC metadata and rio_tiler's rasterio for reading COGs on S3.\n",
    "2. kerchunk + netCDF: The second method uses a (local or S3) kerchunk reference file for NetCDF files stored on S3. The libraries used are xarray for reading the Zarr metadata and rio_tiler's XarrayReader for reading data from the NetCDFs on S3.\n",
    "\n",
    "In the future, the following improvements and additions to this profiling code will be made:\n",
    "\n",
    "1. Test with a Zarr store. The profiling code will be run on a Zarr store to compare the performance of reading from a Zarr store vs. reading from a NetCDF via kerchunk.\n",
    "2. Test different chunking strategies: The profiling code will be run on a few different Zarr stores with different chunking schemes.\n",
    "3. Test a higher resolution dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c1361-1e28-42a6-92b5-7c4bac4d9211",
   "metadata": {},
   "source": [
    "## Setup / Step 0\n",
    "\n",
    "1. Load some basic libraries\n",
    "2. Set an initial tile to test\n",
    "3. Add some AWS credentials\n",
    "4. Install any missing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cbd0f3-f88e-4c4e-b809-eecda8f5c14f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "import cmip6_zarr.eodc_hub_role\n",
    "from matplotlib.pyplot import imshow\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f855b1-e765-41a4-9da9-fec2e0ec106f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad234dcc-b346-4f62-bce1-d3c866911b1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xyz_tile = (0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f1561b-185d-47dc-9b32-ca2d80f84e25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "temporal_resolution = \"daily\"\n",
    "model = \"GISS-E2-1-G\"\n",
    "variable = \"tas\"\n",
    "anon=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a131851",
   "metadata": {},
   "source": [
    "## Profile titiler-pgstac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec854450-c3d7-4cce-9379-13384fcc1b7b",
   "metadata": {},
   "source": [
    "To achieve the best performance, we set some GDAL environment variables.\n",
    "\n",
    "These variables are documented here https://developmentseed.org/titiler/advanced/performance_tuning/, but that advice is copied into comments below for ease of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68399603-1a76-4cb6-a1fb-f00c35f41c3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By default GDAL reads the first 16KB of the file, then if that doesn't contain the entire metadata\n",
    "# it makes one more request for the rest of the metadata.\n",
    "# In environments where latency is relatively high, AWS S3,\n",
    "# it may be beneficial to increase this value depending on the data you expect to read.\n",
    "os.environ['GDAL_INGESTED_BYTES_AT_OPEN'] = '32768'\n",
    "\n",
    "# It's much better to set EMPTY_DIR because this prevents GDAL from making a LIST request.\n",
    "# LIST requests are made for sidecar files, which does not apply for COGs\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "\n",
    "# Tells GDAL to merge consecutive range GET requests.\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES'] = 'YES'\n",
    "\n",
    "# When set to YES, this attempts to download multiple range requests in parallel, reusing the same TCP connection. \n",
    "# Note this is only possible when the server supports HTTP2, which many servers don't yet support.\n",
    "# There's no downside to setting YES here.\n",
    "os.environ['GDAL_HTTP_MULTIPLEX'] = 'YES'\n",
    "os.environ['GDAL_HTTP_VERSION'] = '2'\n",
    "\n",
    "# Setting this to TRUE enables GDAL to use an internal caching mechanism. It's recommended (strongly).\n",
    "os.environ['VSI_CACHE'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc702b3-f418-4281-a8e2-2fe0358d4e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install morecantile==3.4.0 loguru titiler titiler-pgstac\n",
    "#!pip install psycopg psycopg_binary psycopg_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045ea6a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment this line if using a local database\n",
    "# os.environ['LOCAL'] == 'True'\n",
    "\n",
    "# useful to always reload the module while its being developed\n",
    "\n",
    "from cmip6_zarr import eodc_hub_role\n",
    "credentials = eodc_hub_role.fetch_and_set_credentials()\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = credentials['AccessKeyId']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = credentials['SecretAccessKey']\n",
    "os.environ['AWS_SESSION_TOKEN'] = credentials['SessionToken'] \n",
    "from profiler.main import cprofile_list_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b8d9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import cmip6_pgstac.profile_pgstac as profile_pgstac\n",
    "\n",
    "if temporal_resolution == 'daily':\n",
    "    collection = f\"CMIP6_daily_{model}_{variable}\"\n",
    "elif temporal_resolution == 'monthly':\n",
    "    collection = f\"CMIP6_ensemble_monthly_median_{variable}\"\n",
    "\n",
    "query = {\n",
    "  \"collections\": [ collection ],\n",
    "  \"filter\": {\n",
    "    \"op\": \"t_intersects\",\n",
    "    \"args\": [\n",
    "      {\n",
    "        \"property\": \"datetime\"\n",
    "      },\n",
    "      {\n",
    "        \"interval\": [\n",
    "          \"1950-04-01T00:00:00Z\"           \n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"filter-lang\": \"cql2-json\"\n",
    "}\n",
    "\n",
    "image_and_assets, cprofile = profile_pgstac.tile(*xyz_tile, query=dict(query))\n",
    "cprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ab98f-1583-45c4-93b0-da36cf334149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_times = cprofile_list_to_dict(cprofile['cprofile'][1:])\n",
    "total_time = list(all_times.values())[0]['tottime']\n",
    "total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b54282",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "\n",
    "* There are 2 parts to the overall timing of generating the image - `pgstac-search` and `get_tile`.\n",
    "* `get_tile` above is a list with a timing for each tif. The bulk of this time is in `CustomSTACReader#tile`. That function has a subfunction `_reader` which wraps `src_dst.tile` in `self.reader`.\n",
    "* The `CustomSTACReader`'s `reader` attribute is `BaseReader` from `rio_tiler.io.base`. There is no init function for BaseReader so I don't think any time is spent initializing the reader.\n",
    "* `CustomSTACReader` inherits from `MultiBaseReader` so the `#tile` function is defined in that class.\n",
    "* The `MultiBaseReader#tile` function also has a `_reader` subfunction which is called for each asset.\n",
    "* The code for rio_tiler's `MultiBaseReader#tile#_reader` can be thought of as a **initialize reader** step and a **tile** step. \n",
    "* The bulk of the `get_tile` time is spent in the **initialize reader** step of `MultiBaseReader#tile#_reader`. The initialization of `MultiBaseReader#reader` spends most of it's time in `rasterio.open`. I have not dug into the subcalls of `rasterio.open`\n",
    "* `MultiBaseReader#tile#tile` is roughly equivalent to `rasterio.io.reader#part` and wraps the reading of the WarpedVRT, so should be the sum of the previous calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1855e96-3d84-4ae3-a677-10fffb002dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = image_and_assets[0].data_as_image()\n",
    "# data_as_image() returns a numpy.ndarray in form of (col, row, band)\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021ba14",
   "metadata": {},
   "source": [
    "# Profile titiler-xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60aad91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# useful to always reload the module while its being developed\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import xarray_tile_reader\n",
    "import zarr_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af214f31-8602-4c2f-bf67-e5be497c85c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each store, run the test and add to a results table.\n",
    "\n",
    "Each store should be tested `n` times and the mean should be reported for the time of reading the zarr store and reprojecting the data\n",
    "\n",
    "`tile`, `chunk_size`, `reading dataset` `reproject` and `total_time` should be reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b64be1ae-02b4-445c-842b-ea033d8ef53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kerchunk': {'data_store_path': 'combined_CMIP6_daily_GISS-E2-1-G_tas_kerchunk.json'},\n",
       " '600_1440_1': {'data_store_path': '600_1440_1/CMIP6_daily_GISS-E2-1-G_tas.zarr'},\n",
       " '600_1440_29': {'data_store_path': '600_1440_29/CMIP6_daily_GISS-E2-1-G_tas.zarr'},\n",
       " '365_262_262': {'data_store_path': '365_262_262/CMIP6_daily_GISS-E2-1-G_tas.zarr'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = 'nasa-eodc-data-store'\n",
    "chunk_set_paths = ['600_1440_1', '600_1440_29', '365_262_262']\n",
    "results_df = {\n",
    "  'kerchunk': {\n",
    "      \"data_store_path\": f\"combined_CMIP6_{temporal_resolution}_{model}_{variable}_kerchunk.json\"\n",
    "  }\n",
    "}\n",
    "\n",
    "for chunk_set_path in chunk_set_paths:\n",
    "    results_df[chunk_set_path] = {\n",
    "        'data_store_path': f\"{chunk_set_path}/CMIP6_{temporal_resolution}_{model}_{variable}.zarr\"\n",
    "    }\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71c2f689-1da9-4ea2-a07a-450bfbe8cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kerchunk': {'data_store_path': 'combined_CMIP6_daily_GISS-E2-1-G_tas_kerchunk.json',\n",
       "  'chunk_size_mb': 3.2958984375,\n",
       "  'timings': {'time_to_open (ms)': 45.19,\n",
       "   'rio.reproject (ms)': 74.76,\n",
       "   'total_time (ms)': 192.57}},\n",
       " '600_1440_1': {'data_store_path': '600_1440_1/CMIP6_daily_GISS-E2-1-G_tas.zarr',\n",
       "  'chunk_size_mb': 3.2958984375,\n",
       "  'timings': {'time_to_open (ms)': 1817.47,\n",
       "   'rio.reproject (ms)': 73.47,\n",
       "   'total_time (ms)': 1963.43}},\n",
       " '600_1440_29': {'data_store_path': '600_1440_29/CMIP6_daily_GISS-E2-1-G_tas.zarr',\n",
       "  'chunk_size_mb': 95.5810546875,\n",
       "  'timings': {'time_to_open (ms)': 135.65,\n",
       "   'rio.reproject (ms)': 519.13,\n",
       "   'total_time (ms)': 724.5}},\n",
       " '365_262_262': {'data_store_path': '365_262_262/CMIP6_daily_GISS-E2-1-G_tas.zarr',\n",
       "  'chunk_size_mb': 95.57746887207031,\n",
       "  'timings': {'time_to_open (ms)': 79.57,\n",
       "   'rio.reproject (ms)': 1175.34,\n",
       "   'total_time (ms)': 1325.78}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from profiler.main import Timer\n",
    "\n",
    "for dataset in results_df.keys():\n",
    "    data_store_path = results_df[dataset]['data_store_path']\n",
    "    data_store_url = f\"s3://{bucket}/{data_store_path}\"\n",
    "    reference = False\n",
    "    if dataset == 'kerchunk':\n",
    "        reference = True\n",
    "\n",
    "    ds = zarr_reader.xarray_open_dataset(data_store_url, anon=False, reference=reference)\n",
    "\n",
    "    dask_array = ds[0][variable]\n",
    "    chunk_size_bytes = dask_array.dtype.itemsize * dask_array.chunks[0][0] * dask_array.chunks[1][0] * dask_array.chunks[2][0]\n",
    "    chunk_size_mb = chunk_size_bytes / (1024 * 1024)\n",
    "    results_df[dataset]['chunk_size_mb'] = chunk_size_mb\n",
    "\n",
    "    with Timer() as t:\n",
    "        image_and_timings, cprofile = xarray_tile_reader.tile(\n",
    "            data_store_url,\n",
    "            *xyz_tile,\n",
    "            reference=reference,\n",
    "            anon=False,\n",
    "            variable=variable,\n",
    "        )\n",
    "    total_time = round(t.elapsed * 1000, 2)\n",
    "\n",
    "    timings = image_and_timings[1]\n",
    "    results_df[dataset]['timings'] = {}\n",
    "\n",
    "    results_df[dataset]['timings'] = {\n",
    "        'time_to_open (ms)': timings['time_to_open'],\n",
    "        'rio.reproject (ms)': timings['rio.reproject'],\n",
    "        'total_time (ms)': total_time\n",
    "    }\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
