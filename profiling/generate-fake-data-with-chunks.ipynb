{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b69a0d-6113-4cad-ac2b-9cb841ebebbd",
   "metadata": {},
   "source": [
    "# Generate fake data with the same chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c7aa2-ec7a-4356-a596-4cf1f4cf40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/jbusecke/pangeo-forge-recipes@dynamic_chunks_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6086a1-8af0-4afd-8929-e8b739e47749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "from pangeo_forge_recipes import aggregation, dynamic_target_chunks\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import zarr_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1f5225-ba53-4cfb-accf-fb249d1f5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake data directory\n",
    "fake_data_dir = 'fake_data_with_chunks'\n",
    "\n",
    "# Define dimensions\n",
    "time_steps = 1\n",
    "y = 600\n",
    "x = 1200\n",
    "multiple = 2 # how much do you want the dataset to grow by each iteration\n",
    "n_multiples = 12\n",
    "\n",
    "target_chunk_size = '5MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1728aa5-871b-4ad3-91f1-51166902e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 600, 'lon': 1200}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 424, 'lon': 1697}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 848, 'lon': 848}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 1199, 'lon': 533}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 1199, 'lon': 436}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "{'time': 1, 'lat': 69, 'lon': 7673}\n",
      "target_chunks_aspect_ratio_chunked_only={'lat': 1, 'lon': 2}\n",
      "unchunked_dims=['time']\n",
      "Could not find any chunk combinations satisfying the size constraint. Consider increasing size_tolerance or enabling allow_fallback_algo.\n"
     ]
    }
   ],
   "source": [
    "for n_multiple in range(n_multiples):\n",
    "    if n_multiple == 0:\n",
    "        size = y * x        \n",
    "    else:\n",
    "        size = y * x * multiple\n",
    "\n",
    "    x = round(np.sqrt(2 * size))\n",
    "    y = int(x/2)\n",
    "    data = np.random.random(size=(time_steps, y, x))\n",
    "\n",
    "    # Create Xarray datasets with dimensions and coordinates\n",
    "    ds = xr.Dataset({\n",
    "        'data': (['time', 'lat', 'lon'], data),\n",
    "    }, coords={\n",
    "        'time': np.arange(time_steps),\n",
    "        'lat': np.linspace(-90, 90, y),\n",
    "        'lon': np.linspace(-180, 180, x)\n",
    "    })\n",
    "\n",
    "    d = ds.to_dict(data=False)\n",
    "    schema = aggregation.XarraySchema(\n",
    "        attrs=d.get(\"attrs\"),\n",
    "        coords=d.get(\"coords\"),\n",
    "        data_vars=d.get(\"data_vars\"),\n",
    "        dims=d.get(\"dims\"),\n",
    "        chunks=d.get(\"chunks\", {}),\n",
    "    )\n",
    "    try:\n",
    "        target_chunks = dynamic_target_chunks.dynamic_target_chunks_from_schema(\n",
    "            schema,\n",
    "            target_chunk_size=target_chunk_size,\n",
    "            target_chunks_aspect_ratio={'time': -1, 'lat': 1, 'lon': 2},\n",
    "            size_tolerance=0.2\n",
    "        )    \n",
    "        print(target_chunks)\n",
    "        ds = ds.chunk(target_chunks)    \n",
    "        ds.to_zarr(f'{fake_data_dir}/store_lat_{y}x_lon_{x}.zarr', mode='w')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9869f1f-90c2-426c-800a-fe7c192ed61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size for store_lat_4796x_lon_9592.zarr:\n",
      "3.988372802734375\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk size for store_lat_19182x_lon_38365.zarr:\n",
      "4.039283752441406\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk size for store_lat_600x_lon_1200.zarr:\n",
      "5.4931640625\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk size for store_lat_2398x_lon_4797.zarr:\n",
      "4.875694274902344\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk size for store_lat_1696x_lon_3392.zarr:\n",
      "5.486328125\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk size for store_lat_848x_lon_1697.zarr:\n",
      "5.48956298828125\n",
      "--------------------------------------------------------------------------------\n",
      "Could not open .ipynb_checkpoints as a Zarr store. Error: No such file or directory: '/Users/aimeebarciauskas/github/developmentseed/tile-benchmarking/profiling/fake_data_with_chunks/.ipynb_checkpoints'\n"
     ]
    }
   ],
   "source": [
    "# List all items in the directory\n",
    "items = os.listdir(fake_data_dir)\n",
    "\n",
    "# Loop through each item and open it with xarray if it's a Zarr store\n",
    "for item in items:\n",
    "    item_path = os.path.join(fake_data_dir, item)\n",
    "    # Check if the item is a directory (Zarr stores are directories)\n",
    "    if os.path.isdir(item_path):\n",
    "        try:\n",
    "            # Attempt to open the Zarr store using xarray\n",
    "            ds = xr.open_zarr(item_path)\n",
    "            print(f\"Chunk size for {item}:\")\n",
    "            print(zarr_helpers.get_chunk_size(ds['data'])[2])\n",
    "            print('-' * 80)  # Print a separator line\n",
    "        except Exception as e:\n",
    "            # Print an error message if unable to open the Zarr store\n",
    "            print(f\"Could not open {item} as a Zarr store. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42dbc5c-f400-4d16-943e-3a8f206d2b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-profiling",
   "language": "python",
   "name": "venv-profiling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
