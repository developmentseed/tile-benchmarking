{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a2bdcc-0ff4-4d05-a92b-403ae87844aa",
   "metadata": {},
   "source": [
    "# Generate Kerchunk Reference from CMIP6 NetCDF files\n",
    "\n",
    "This notebook demonstrates how to create a kerchunk reference from NetCDF files on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7250a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "import boto3\n",
    "import fsspec\n",
    "import json\n",
    "import os\n",
    "import ujson\n",
    "import xarray as xr\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from kerchunk.hdf import SingleHdf5ToZarr\n",
    "from typing import Dict\n",
    "import sys; sys.path.append('..')\n",
    "import helpers.eodc_hub_role as eodc_hub_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b527e1-b054-4e05-a9b1-b61a7cba4a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials = eodc_hub_role.fetch_and_set_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e335440-5a5e-4740-adda-e4e9cae36baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cfd5b9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Specify the CMIP collection to use (daily or monthly)\n",
    "bucket_name = 'veda-data-store-staging'\n",
    "model = \"GISS-E2-1-G\"\n",
    "variable = \"tas\"\n",
    "anon = True\n",
    "s3_path = f\"s3://nex-gddp-cmip6/NEX-GDDP-CMIP6/{model}/historical/r1i1p1*/{variable}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e3976-a34f-4588-b0b5-2ec2d90835ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 ls s3://nex-gddp-cmip6/NEX-GDDP-CMIP6/{model}/ssp585/r1i1p1f2/tas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7879ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate fsspec filesystems for reading and writing\n",
    "fs_read = fsspec.filesystem(\"s3\", anon=anon, skip_instance_cache=False)\n",
    "fs_write = fsspec.filesystem(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a799e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 discovered from s3://nex-gddp-cmip6/NEX-GDDP-CMIP6/GISS-E2-1-G/historical/r1i1p1*/tas/*\n"
     ]
    }
   ],
   "source": [
    "# Retrieve list of available months\n",
    "files_paths = fs_read.glob(s3_path)\n",
    "print(f\"{len(files_paths)} discovered from {s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "667f134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted([\"s3://\" + f for f in files_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02515b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "so = dict(mode=\"rb\", anon=anon, default_fill_cache=False, default_cache_type=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19b5d8-a153-4054-b541-becfc6fdc22b",
   "metadata": {},
   "source": [
    "# inspecting no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "816c9103-4615-4fe0-99e8-f8b954e2626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "aws_url = all_files[0]\n",
    "\n",
    "fileObj = fs.open(aws_url)\n",
    "ds = xr.open_dataset(fileObj, engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26edf5da-f47a-41e6-a708-6bce81b63cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tas.values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d06adf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# We are creating a temporary directory to store the .json reference files\n",
    "# Alternately, you could write these to cloud storage.\n",
    "td = TemporaryDirectory()\n",
    "temp_dir = td.name\n",
    "print(f\"Writing single file references to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kerchunk's `SingleHdf5ToZarr` method to create a `Kerchunk` index from a NetCDF file.\n",
    "def generate_json_reference(u):\n",
    "    with fs_read.open(u, **so) as infile:\n",
    "        print(infile)\n",
    "        fname = u.split(\"/\")[-1].strip(\".nc\")        \n",
    "        h5chunks = SingleHdf5ToZarr(infile, u, inline_threshold=300)\n",
    "        return fname, ujson.dumps(h5chunks.translate()).encode()\n",
    "    \n",
    "def write_json(fname, reference_json, temp_dir):\n",
    "    outf = os.path.join(temp_dir, f\"{fname}.json\")\n",
    "    with open(outf, \"wb\") as f:\n",
    "        f.write(reference_json)\n",
    "    return outf    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e4d4b-6e9e-4b54-b9b3-730fdf9e54d4",
   "metadata": {},
   "source": [
    "# Test we can create a kerchunk reference for one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcb56a-f4e2-40d1-b485-531083c2184b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname, ref_json = generate_json_reference(all_files[0])\n",
    "write_json(fname, ref_json, temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b7c39-9f13-4e02-8be1-af4de00e35ad",
   "metadata": {},
   "source": [
    "# Start the dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794be824-0833-4229-a8b4-10b071eced26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster, Gateway\n",
    "\n",
    "gateway = Gateway()\n",
    "clusters = gateway.list_clusters()\n",
    "\n",
    "# connect to an existing cluster - this is useful when the kernel shutdown in the middle of an interactive session\n",
    "if clusters:\n",
    "    cluster = gateway.connect(clusters[0].name)\n",
    "else:\n",
    "    cluster = GatewayCluster(shutdown_on_close=True)\n",
    "\n",
    "cluster.scale(16)\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d29770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through filelist to generate Kerchunked files. Good use for `Dask`\n",
    "import dask.bag as db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b4183-5c4f-41ae-9dc9-bb0cc1cb4523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobs = db.map(generate_json_reference, all_files[0:2])\n",
    "bag = db.from_sequence(all_files, partition_size=1)\n",
    "result = db.map(generate_json_reference, bag)\n",
    "all_references = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbd769-c89e-40e6-b295-783149e15224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_files = [write_json(fname, reference_json, temp_dir) for fname, reference_json in all_references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ec232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine individual references into single consolidated reference\n",
    "mzz = MultiZarrToZarr(\n",
    "    output_files,\n",
    "    remote_protocol='s3',\n",
    "    remote_options={'anon': anon},\n",
    "    concat_dims=['time'],\n",
    "    coo_map={\"time\": \"cf:time\"},\n",
    "    inline_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f47dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi_kerchunk = mzz.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9731f-6b19-4d15-a66e-d7668c19efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write kerchunk .json record\n",
    "output_fname = f\"combined_CMIP6_daily_{model}_{variable}_kerchunk.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ced4a6-0c38-43c8-8c6e-a4fff8a9f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = os.path.join(temp_dir, output_fname)\n",
    "with open(f\"{output_location}\", \"wb\") as f:\n",
    "    print(f\"Writing combined kerchunk reference file {output_location}\")\n",
    "    f.write(ujson.dumps(multi_kerchunk).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset as zarr object using fsspec reference file system and Xarray\n",
    "fs = fsspec.filesystem(\n",
    "    \"reference\", fo=multi_kerchunk, remote_protocol=\"s3\", remote_options={\"anon\": anon}\n",
    ")\n",
    "m = fs.get_mapper(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "ds = xr.open_dataset(m, engine=\"zarr\", backend_kwargs=dict(consolidated=False))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70497e-d27c-43e4-b460-83665ccab4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.isel(time=0).tas.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3089a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "response = s3.upload_file(output_location, bucket_name, f'cmip6-{model}-{variable}-kerchunk/{output_fname}')\n",
    "print(f\"Response uploading {output_fname} to {bucket_name} was {response}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdbfb0-bd3d-4abf-8d0f-7cf7d92f7d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://veda-data-store-staging/cmip6-GISS-E2-1-G-tas-kerchunk/combined_CMIP6_daily_GISS-E2-1-G_tas_kerchunk.json"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
